{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a53e1be-1ffb-4795-96e7-e172b1de1dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image  # Импортируем Image из PIL\n",
    "from torchvision import transforms\n",
    "from torchvision.models import vit_b_16  # Импортируем предобученный ViT\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "147eb13e-5425-45e3-a795-2eee5f98cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка предобученной модели Vision Transformer (ViT)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = vit_b_16(weights='DEFAULT')  # Загрузка предобученных весов\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Преобразования для подготовки видео с аугментацией\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Размер, ожидаемый моделью\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Изменение яркости, контрастности и цветового оттенка\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def extract_frames(video_path, num_frames=10):\n",
    "    \"\"\" Извлекает ключевые кадры из видео \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "\n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Конвертируем в RGB\n",
    "            frames.append(Image.fromarray(frame))  # Конвертируем в PIL.Image\n",
    "\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def get_video_features(video_path, num_frames=10):\n",
    "    \"\"\" Извлекает признаки из видео с помощью ViT \"\"\"\n",
    "    frames = extract_frames(video_path, num_frames)\n",
    "    if not frames:\n",
    "        return None\n",
    "    \n",
    "    # Применяем преобразования и извлекаем признаки\n",
    "    features_list = []\n",
    "    for frame in frames:\n",
    "        # Применяем аугментацию и преобразования\n",
    "        transformed_frame = transform(frame).unsqueeze(0).to(device)  # Добавляем размерность батча\n",
    "        with torch.no_grad():  # Отключаем отслеживание градиентов\n",
    "            features = model(transformed_frame).detach().cpu().numpy().flatten()  # Преобразуем в NumPy\n",
    "        features_list.append(features)\n",
    "\n",
    "    # Объединяем признаки всех кадров в один вектор\n",
    "    return np.mean(features_list, axis=0)  # Средние признаки всех кадров\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\" Рассчитывает косинусное расстояние между двумя векторами \"\"\"\n",
    "    if vec1 is None or vec2 is None:\n",
    "        return float('inf')  # Если одно из значений отсутствует\n",
    "    return cosine(vec1, vec2)\n",
    "\n",
    "def find_duplicates(video_dir, threshold=0.3, num_frames=10):\n",
    "    \"\"\" Ищет дубликаты видео в указанной директории по косинусному расстоянию \"\"\"\n",
    "    video_files = [os.path.join(video_dir, f) for f in os.listdir(video_dir) if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv'))]\n",
    "    video_features = {}\n",
    "\n",
    "    # Извлекаем признаки для каждого видео\n",
    "    for video_file in video_files:\n",
    "        features = get_video_features(video_file, num_frames)\n",
    "        video_features[video_file] = features\n",
    "\n",
    "    duplicates = []\n",
    "\n",
    "    # Сравниваем признаки между видео\n",
    "    for i, video_1 in enumerate(video_files):\n",
    "        for j, video_2 in enumerate(video_files):\n",
    "            if i >= j:\n",
    "                continue\n",
    "\n",
    "            distance = cosine_similarity(video_features[video_1], video_features[video_2])\n",
    "\n",
    "            # Проверяем на дубликаты с учетом порога\n",
    "            if distance < threshold:\n",
    "                duplicates.append({\n",
    "                    'video_1': video_1,\n",
    "                    'video_2': video_2,\n",
    "                    'cosine_distance': distance,\n",
    "                })\n",
    "\n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cde34f41-4701-4c68-8f91-880bc13d3799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дубликаты не найдены.\n"
     ]
    }
   ],
   "source": [
    "video_dir = 'video2' \n",
    "threshold_value = 0.1  # Чем меньше - тем точнее!!!!\n",
    "num_frames_to_analyze = 10\n",
    "duplicates = find_duplicates(video_dir, threshold=threshold_value, num_frames=num_frames_to_analyze)\n",
    "\n",
    "# Выводим только дубликаты\n",
    "if duplicates:\n",
    "    for dup in duplicates:\n",
    "        print(f\"Дубликаты найдены: {dup['video_1']} и {dup['video_2']}\")\n",
    "        print(f\"Косинусное расстояние: {dup['cosine_distance']}\\n\")\n",
    "else:\n",
    "    print(\"Дубликаты не найдены.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
