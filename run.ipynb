{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e728ea0-8695-4f9e-b958-fd93863689f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "os.chdir('/home/user1')\n",
    "json.dump({}, open('Hakaton/models/database.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7085a59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from video_2 import extract_video_embedding_2, create_video_model\n",
    "from VIT_2 import get_video_embedding, create_vit_model\n",
    "from audio_2 import extract_audio_embeddings_from_video2, create_audio_model\n",
    "from sklearn.metrics import f1_score\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import urllib\n",
    "\n",
    "def check_dupl_from_db(vid_emb, vit_emb, aud_emb, database, thresholds_vid=(0.8, 0.95), thresholds_aud=(0.8, 0.95)):\n",
    "    duplicates = []\n",
    "    for uuid in database.keys():\n",
    "        orig_vid_emb = np.array(database[uuid]['vid_emb'])\n",
    "        orig_vit_emb = np.array(database[uuid]['vit_emb'])\n",
    "        orig_aud_emb = np.array(database[uuid]['aud_emb'])\n",
    "        if vid_emb is not None and orig_vid_emb is not None:\n",
    "            try:\n",
    "                similarity_vid = cosine_similarity(vid_emb.reshape(1, -1), orig_vid_emb.reshape(1, -1)).max(axis=1).mean()\n",
    "            except:\n",
    "                similarity_vid = None\n",
    "        else:\n",
    "            similarity_vid = None\n",
    "        if vit_emb is not None and orig_vit_emb is not None:\n",
    "            try:\n",
    "                similarity_vit = cosine_similarity(vit_emb.reshape(1, -1), orig_vit_emb.reshape(1, -1)).max(axis=1).mean()\n",
    "            except:\n",
    "                similarity_vit = None\n",
    "        else:\n",
    "            similarity_vit = None            \n",
    "        if aud_emb is not None and orig_aud_emb is not None:\n",
    "            try:\n",
    "                similarity_aud = cosine_similarity(aud_emb.reshape(1, -1), orig_aud_emb.reshape(1, -1)).max(axis=1).mean() \n",
    "            except:\n",
    "                similarity_aud = None\n",
    "        else:\n",
    "            similarity_aud = None \n",
    "        similarity_vid = np.nanmean([similarity_vid, similarity_vit])\n",
    "        if similarity_vid is None and similarity_aud is None:\n",
    "            continue\n",
    "        if similarity_aud is None:\n",
    "            if similarity_vid > thresholds_vid[0]:\n",
    "                duplicates.append((uuid, similarity_vid, similarity_aud))\n",
    "                continue\n",
    "        if similarity_vid is None:\n",
    "            if similarity_aud > thresholds_aud[0]:\n",
    "                duplicates.append((uuid, similarity_vid, similarity_aud))\n",
    "                continue\n",
    "        if similarity_vid > thresholds_vid[0] and similarity_aud > thresholds_aud[0]:\n",
    "            duplicates.append((uuid, similarity_vid, similarity_aud))\n",
    "        if similarity_vid > thresholds_vid[1] and similarity_aud < thresholds_aud[0]:\n",
    "            duplicates.append((uuid, similarity_vid, similarity_aud))\n",
    "            \n",
    "    return duplicates\n",
    "\n",
    "def find_duplicate_videos(video_file, database_path='database.json', model_name = 'resnet50', sample_frames=10, frame_size=(224, 224), threshold=0.9):\n",
    "    database = json.load(open(database_path)) #БД с эмбеддингами\n",
    "    #Модель для видеоряда\n",
    "    model_vid = create_video_model()\n",
    "    #model_vid = torch.nn.Sequential(*(list(model_vid.children())[:-1])) \n",
    "    #model_vid.eval()\n",
    "    #Считаем метрики\n",
    "    pred = []\n",
    "    pred_uuid = []\n",
    "\n",
    "    #Модель для аудиоряда\n",
    "    model_aud = create_audio_model()\n",
    "    model_vit = create_vit_model()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    updated = False\n",
    "\n",
    "    #metadata = new_train#train.loc[train['uuid'].isin(['5eb4127e-5694-492b-963c-6688522e9ad2', '3726bb2d-3323-41f8-8eb2-0d7cf095d62b'])].sort_values('created')\n",
    "    #Перебираем все файлы с видео\n",
    "    #for video_file in tqdm(video_files, desc=\"Extracting video features\"):\n",
    "    if updated:\n",
    "        database = json.load(open(database_path)) #БД с эмбеддингами\n",
    "        updated = False\n",
    "    #audio_embeddings = {}\n",
    "    #duplicates = []\n",
    "    #video_file = os.path.join(video_folder, row.link.split('/')[-1])\n",
    "    # Путь для временного хранения аудио\n",
    "    #temp_audio_path = os.path.join(f\"{video_file}.wav\")\n",
    "    #Получаем аудио эмбеддинг\n",
    "    \n",
    "\n",
    "    audio_embedding = extract_audio_embeddings_from_video2(video_file, model_aud)\n",
    "    #Получаем видео эмбеддинг\n",
    "    video_features = extract_video_embedding_2(video_file, model_vid)\n",
    "    vit_embedding = get_video_embedding(video_file, model_vit)\n",
    "    #Ищем оригинал в БД\n",
    "    duplicates = check_dupl_from_db(video_features, vit_embedding, audio_embedding, database=database)\n",
    "    #Если есть выводим, иначе записываем новый оригинал в БД\n",
    "    if duplicates:\n",
    "        duplicates.sort(key=lambda x: np.mean([x[1], x[2]]))\n",
    "        pred.append(1)\n",
    "        pred_uuid.append(duplicates[-1][0])\n",
    "        #print(f'Дубликат: {video_file}, оригинал: {duplicates}') \n",
    "    else:\n",
    "        pred.append(0)\n",
    "        pred_uuid.append(np.nan)\n",
    "        if video_features is not None:\n",
    "            vid_emb = video_features.tolist()\n",
    "        else:\n",
    "            vid_emb = None\n",
    "        if vit_embedding is not None:\n",
    "            vit_emb = vit_embedding.tolist()\n",
    "        else:\n",
    "            vid_emb = None                \n",
    "        if audio_embedding is not None:\n",
    "            aud_emb = audio_embedding.tolist()\n",
    "        else:\n",
    "            aud_emb = None\n",
    "        new_origin = {video_file.split('/')[-1]: {'vid_emb': vid_emb,\n",
    "                                 'vit_emb': vit_emb,\n",
    "                                 'aud_emb': aud_emb}}\n",
    "        database.update(new_origin)\n",
    "        json.dump(database, open(database_path, 'w'))\n",
    "        updated = True\n",
    "        #print('Добавили в БД:', row.uuid)\n",
    "                \n",
    "\n",
    "            \n",
    "       # if os.path.exists(temp_audio_path):\n",
    "            #os.remove(temp_audio_path)\n",
    "    return pred, pred_uuid\n",
    "\n",
    "def run(path2video):\n",
    "    os.chdir('/home/user1')\n",
    "    #path2video = os.path.join('Hakaton/models/test', url_link.split('/')[-1])\n",
    "    #urllib.request.urlretrieve(url_link, path2video) \n",
    "    pred, pred_uuid = find_duplicate_videos(path2video, database_path='Hakaton/models/database.json')\n",
    "    return pred, pred_uuid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7c62973-9880-407f-b4a4-4074247a3c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "run('https://s3.ritm.media/yappy-db-duplicates/3726bb2d-3323-41f8-8eb2-0d7cf095d62b.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e1ef60a-952c-4931-93d1-e4cfa3e59b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1], ['test.mp4'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run('https://s3.ritm.media/yappy-db-duplicates/5eb4127e-5694-492b-963c-6688522e9ad2.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
